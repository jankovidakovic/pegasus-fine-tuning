{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset cnn_dailymail (/home/jvidakovic/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fbd42f3f3173459db52a68b4dc906fa2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from transformers import PegasusTokenizerFast\n",
    "\n",
    "model_name = \"google/pegasus-large\"\n",
    "tokenizer = PegasusTokenizerFast.from_pretrained(model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mjankovidakovic\u001B[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.12.14"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/home/jvidakovic/pegasus-fine-tuning/wandb/run-20220416_120144-23hjoqit</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href=\"https://wandb.ai/jankovidakovic/pegasus-cnn-fine-tuning/runs/23hjoqit\" target=\"_blank\">wobbly-sun-4</a></strong> to <a href=\"https://wandb.ai/jankovidakovic/pegasus-cnn-fine-tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/jankovidakovic/pegasus-cnn-fine-tuning/runs/23hjoqit?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>",
      "text/plain": "<wandb.sdk.wandb_run.Run at 0x7f6346412df0>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"pegasus-cnn-fine-tuning\", entity=\"jankovidakovic\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from utils import prepare_dataset\n",
    "\n",
    "eval_dataset = prepare_dataset(\n",
    "    dataset[\"validation\"][\"article\"],\n",
    "    dataset[\"validation\"][\"highlights\"],\n",
    "    tokenizer=tokenizer\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_dataset = prepare_dataset(\n",
    "    dataset[\"train\"][\"article\"],\n",
    "    dataset[\"train\"][\"highlights\"],\n",
    "    tokenizer=tokenizer\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "dict"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item = train_dataset[0]\n",
    "type(item)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['input_ids', 'attention_mask', 'labels'])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([10298,  1571,   151,  ...,     0,     0,     0])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item[\"labels\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from utils import prepare_model\n",
    "\n",
    "model, optimizer, scheduler = prepare_model(device=\"cuda\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, IntervalStrategy\n",
    "\n",
    "output_dir = \"./results\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,  # output directory\n",
    "    per_device_train_batch_size=1,  # batch size per device during training, can increase if memory allows\n",
    "    per_device_eval_batch_size=1,  # batch size for evaluation, can increase if memory allows\n",
    "    save_steps=500,  # number of updates steps before checkpoint saves\n",
    "    save_total_limit=3,  # limit the total amount of checkpoints and deletes the older checkpoints\n",
    "    evaluation_strategy=IntervalStrategy.STEPS,  # evaluation strategy to adopt during training\n",
    "    eval_steps=100,  # number of update steps before evaluation\n",
    "    # warmup_steps=500,  # number of warmup steps for learning rate scheduler\n",
    "    # weight_decay=0.01,  # strength of weight decay\n",
    "    logging_dir='./logs',  # directory for storing logs\n",
    "    logging_steps=10,\n",
    "    #####\n",
    "    label_smoothing_factor=0.1,\n",
    "    max_steps=170000,\n",
    "    # per_device_train_batch_size=1,  # total batch size = 2\n",
    "    gradient_accumulation_steps=128,   # batch_size_orig / batch_size_possible\n",
    "    report_to=[\"wandb\"],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/google/pegasus-large/resolve/main/spiece.model from cache at /home/jvidakovic/.cache/huggingface/transformers/66f187d645734a6204f3fd24593fbf0d9e36b528dd85b3adae9a566b17b4768f.1acf68c74589da6c7fa3548093824dfc450a54637f4356929bbfea7e294a68f8\n",
      "loading file https://huggingface.co/google/pegasus-large/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/google/pegasus-large/resolve/main/special_tokens_map.json from cache at /home/jvidakovic/.cache/huggingface/transformers/fbf9c7cf2d49b24712b53a2760e7c62a2acecd1496908822df00b8ec2683ca6d.294ebaa4cd17bb284635004c92d2c4d522ec488c828dcce0c2471b6f28e3fe82\n",
      "loading file https://huggingface.co/google/pegasus-large/resolve/main/tokenizer_config.json from cache at /home/jvidakovic/.cache/huggingface/transformers/74256fafbb3cb536e351e6731914d42f732e77d33e537b6c19fb72f4b74f50ea.43f396f0ee3b974f9128267d49f69a26b11f3ed290851ac5788a549cc2979671\n",
      "loading configuration file https://huggingface.co/google/pegasus-large/resolve/main/config.json from cache at /home/jvidakovic/.cache/huggingface/transformers/3fa0446657dd3714a950ba400a3fa72686d0f815da436514e4823a973ef23e20.f2dc0735a07d1a70170e8e0e4d5fb57ad90d8ea5201a0dbd4b33f2f499444852\n",
      "Model config PegasusConfig {\n",
      "  \"_name_or_path\": \"google/pegasus-large\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"PegasusForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 16,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 16,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 1,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 0.8,\n",
      "  \"max_length\": 256,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"pegasus\",\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 8,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization_aeslc\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 32,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_arxiv\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_big_patent\": {\n",
      "      \"length_penalty\": 0.7,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_billsum\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_cnn_dailymail\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_gigaword\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 32,\n",
      "      \"max_position_embeddings\": 128\n",
      "    },\n",
      "    \"summarization_large\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_multi_news\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_newsroom\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_pubmed\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_reddit_tifu\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_wikihow\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 64,\n",
      "      \"max_position_embeddings\": 512\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 96103\n",
      "}\n",
      "\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, PegasusTokenizer\n",
    "\n",
    "trainer = Trainer(\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    # tokenizer=tokenizer,\n",
    "    tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-large\"),\n",
    "    model=model,\n",
    "    # compute_metrics=\"hehe\"  # i suppose computing rouge on every step is overkill\n",
    "    optimizers=(optimizer, scheduler),\n",
    "    args=training_args\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
      "***** Running training *****\n",
      "  Num examples = 287113\n",
      "  Num Epochs = 152\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "  Gradient Accumulation steps = 128\n",
      "  Total optimization steps = 170000\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Caught ValueError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/jvidakovic/.conda/envs/seminar-2/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/jvidakovic/.conda/envs/seminar-2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/jvidakovic/.conda/envs/seminar-2/lib/python3.9/site-packages/transformers/models/pegasus/modeling_pegasus.py\", line 1392, in forward\n    outputs = self.model(\n  File \"/home/jvidakovic/.conda/envs/seminar-2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/jvidakovic/.conda/envs/seminar-2/lib/python3.9/site-packages/transformers/models/pegasus/modeling_pegasus.py\", line 1249, in forward\n    decoder_outputs = self.decoder(\n  File \"/home/jvidakovic/.conda/envs/seminar-2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/jvidakovic/.conda/envs/seminar-2/lib/python3.9/site-packages/transformers/models/pegasus/modeling_pegasus.py\", line 1010, in forward\n    raise ValueError(\"You have to specify either decoder_input_ids or decoder_inputs_embeds\")\nValueError: You have to specify either decoder_input_ids or decoder_inputs_embeds\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [17]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/seminar-2/lib/python3.9/site-packages/transformers/trainer.py:1422\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   1420\u001B[0m         tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining_step(model, inputs)\n\u001B[1;32m   1421\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1422\u001B[0m     tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1424\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   1425\u001B[0m     args\u001B[38;5;241m.\u001B[39mlogging_nan_inf_filter\n\u001B[1;32m   1426\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_tpu_available()\n\u001B[1;32m   1427\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (torch\u001B[38;5;241m.\u001B[39misnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch\u001B[38;5;241m.\u001B[39misinf(tr_loss_step))\n\u001B[1;32m   1428\u001B[0m ):\n\u001B[1;32m   1429\u001B[0m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[1;32m   1430\u001B[0m     tr_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m tr_loss \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_globalstep_last_logged)\n",
      "File \u001B[0;32m~/.conda/envs/seminar-2/lib/python3.9/site-packages/transformers/trainer.py:2011\u001B[0m, in \u001B[0;36mTrainer.training_step\u001B[0;34m(self, model, inputs)\u001B[0m\n\u001B[1;32m   2008\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loss_mb\u001B[38;5;241m.\u001B[39mreduce_mean()\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m   2010\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mautocast_smart_context_manager():\n\u001B[0;32m-> 2011\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2013\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mn_gpu \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   2014\u001B[0m     loss \u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mmean()  \u001B[38;5;66;03m# mean() to average on multi-gpu parallel training\u001B[39;00m\n",
      "File \u001B[0;32m~/.conda/envs/seminar-2/lib/python3.9/site-packages/transformers/trainer.py:2043\u001B[0m, in \u001B[0;36mTrainer.compute_loss\u001B[0;34m(self, model, inputs, return_outputs)\u001B[0m\n\u001B[1;32m   2041\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   2042\u001B[0m     labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 2043\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2044\u001B[0m \u001B[38;5;66;03m# Save past state if it exists\u001B[39;00m\n\u001B[1;32m   2045\u001B[0m \u001B[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001B[39;00m\n\u001B[1;32m   2046\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mpast_index \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/.conda/envs/seminar-2/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/.conda/envs/seminar-2/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:168\u001B[0m, in \u001B[0;36mDataParallel.forward\u001B[0;34m(self, *inputs, **kwargs)\u001B[0m\n\u001B[1;32m    166\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodule(\u001B[38;5;241m*\u001B[39minputs[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m    167\u001B[0m replicas \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreplicate(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodule, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice_ids[:\u001B[38;5;28mlen\u001B[39m(inputs)])\n\u001B[0;32m--> 168\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparallel_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreplicas\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    169\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgather(outputs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_device)\n",
      "File \u001B[0;32m~/.conda/envs/seminar-2/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:178\u001B[0m, in \u001B[0;36mDataParallel.parallel_apply\u001B[0;34m(self, replicas, inputs, kwargs)\u001B[0m\n\u001B[1;32m    177\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mparallel_apply\u001B[39m(\u001B[38;5;28mself\u001B[39m, replicas, inputs, kwargs):\n\u001B[0;32m--> 178\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mparallel_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreplicas\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice_ids\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mreplicas\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/seminar-2/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py:86\u001B[0m, in \u001B[0;36mparallel_apply\u001B[0;34m(modules, inputs, kwargs_tup, devices)\u001B[0m\n\u001B[1;32m     84\u001B[0m     output \u001B[38;5;241m=\u001B[39m results[i]\n\u001B[1;32m     85\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(output, ExceptionWrapper):\n\u001B[0;32m---> 86\u001B[0m         \u001B[43moutput\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreraise\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     87\u001B[0m     outputs\u001B[38;5;241m.\u001B[39mappend(output)\n\u001B[1;32m     88\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "File \u001B[0;32m~/.conda/envs/seminar-2/lib/python3.9/site-packages/torch/_utils.py:457\u001B[0m, in \u001B[0;36mExceptionWrapper.reraise\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    453\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m    454\u001B[0m     \u001B[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001B[39;00m\n\u001B[1;32m    455\u001B[0m     \u001B[38;5;66;03m# instantiate since we don't know how to\u001B[39;00m\n\u001B[1;32m    456\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m--> 457\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exception\n",
      "\u001B[0;31mValueError\u001B[0m: Caught ValueError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/jvidakovic/.conda/envs/seminar-2/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/jvidakovic/.conda/envs/seminar-2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/jvidakovic/.conda/envs/seminar-2/lib/python3.9/site-packages/transformers/models/pegasus/modeling_pegasus.py\", line 1392, in forward\n    outputs = self.model(\n  File \"/home/jvidakovic/.conda/envs/seminar-2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/jvidakovic/.conda/envs/seminar-2/lib/python3.9/site-packages/transformers/models/pegasus/modeling_pegasus.py\", line 1249, in forward\n    decoder_outputs = self.decoder(\n  File \"/home/jvidakovic/.conda/envs/seminar-2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/jvidakovic/.conda/envs/seminar-2/lib/python3.9/site-packages/transformers/models/pegasus/modeling_pegasus.py\", line 1010, in forward\n    raise ValueError(\"You have to specify either decoder_input_ids or decoder_inputs_embeds\")\nValueError: You have to specify either decoder_input_ids or decoder_inputs_embeds\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}