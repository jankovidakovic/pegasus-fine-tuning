{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "Metric(name: \"rouge\", features: {'predictions': Value(dtype='string', id='sequence'), 'references': Value(dtype='string', id='sequence')}, usage: \"\"\"\nCalculates average rouge scores for a list of hypotheses and references\nArgs:\n    predictions: list of predictions to score. Each predictions\n        should be a string with tokens separated by spaces.\n    references: list of reference for each prediction. Each\n        reference should be a string with tokens separated by spaces.\n    rouge_types: A list of rouge types to calculate.\n        Valid names:\n        `\"rouge{n}\"` (e.g. `\"rouge1\"`, `\"rouge2\"`) where: {n} is the n-gram based scoring,\n        `\"rougeL\"`: Longest common subsequence based scoring.\n        `\"rougeLSum\"`: rougeLsum splits text using `\"\n\"`.\n        See details in https://github.com/huggingface/datasets/issues/617\n    use_stemmer: Bool indicating whether Porter stemmer should be used to strip word suffixes.\n    use_agregator: Return aggregates if this is set to True\nReturns:\n    rouge1: rouge_1 (precision, recall, f1),\n    rouge2: rouge_2 (precision, recall, f1),\n    rougeL: rouge_l (precision, recall, f1),\n    rougeLsum: rouge_lsum (precision, recall, f1)\nExamples:\n\n    >>> rouge = datasets.load_metric('rouge')\n    >>> predictions = [\"hello there\", \"general kenobi\"]\n    >>> references = [\"hello there\", \"general kenobi\"]\n    >>> results = rouge.compute(predictions=predictions, references=references)\n    >>> print(list(results.keys()))\n    ['rouge1', 'rouge2', 'rougeL', 'rougeLsum']\n    >>> print(results[\"rouge1\"])\n    AggregateScore(low=Score(precision=1.0, recall=1.0, fmeasure=1.0), mid=Score(precision=1.0, recall=1.0, fmeasure=1.0), high=Score(precision=1.0, recall=1.0, fmeasure=1.0))\n    >>> print(results[\"rouge1\"].mid.fmeasure)\n    1.0\n\"\"\", stored examples: 0)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = load_metric(\"rouge\")\n",
    "metric"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "{'rouge1': AggregateScore(low=Score(precision=0.8333333333333334, recall=0.8333333333333334, fmeasure=0.8333333333333334), mid=Score(precision=0.8333333333333334, recall=0.8333333333333334, fmeasure=0.8333333333333334), high=Score(precision=0.8333333333333334, recall=0.8333333333333334, fmeasure=0.8333333333333334)),\n 'rouge2': AggregateScore(low=Score(precision=0.6, recall=0.6, fmeasure=0.6), mid=Score(precision=0.6, recall=0.6, fmeasure=0.6), high=Score(precision=0.6, recall=0.6, fmeasure=0.6)),\n 'rougeL': AggregateScore(low=Score(precision=0.8333333333333334, recall=0.8333333333333334, fmeasure=0.8333333333333334), mid=Score(precision=0.8333333333333334, recall=0.8333333333333334, fmeasure=0.8333333333333334), high=Score(precision=0.8333333333333334, recall=0.8333333333333334, fmeasure=0.8333333333333334)),\n 'rougeLsum': AggregateScore(low=Score(precision=0.8333333333333334, recall=0.8333333333333334, fmeasure=0.8333333333333334), mid=Score(precision=0.8333333333333334, recall=0.8333333333333334, fmeasure=0.8333333333333334), high=Score(precision=0.8333333333333334, recall=0.8333333333333334, fmeasure=0.8333333333333334))}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [\"Hello.\\nThis is a second sentence.\"]\n",
    "references = [\"Hello.\\nThis is a first sentence.\"]\n",
    "rouge_types = [\"rouge1, rouge2, rougeL, rougeLSum\"]\n",
    "metric.compute(predictions=predictions, references=references, use_stemmer=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset cnn_dailymail (/home/jvidakovic/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5bed5dc23b164da99da453446f8601b2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
    "train_texts, train_labels = dataset['train']['article'], dataset['train']['highlights']\n",
    "val_texts, val_labels = dataset[\"validation\"][\"article\"], dataset[\"validation\"][\"highlights\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "'Syrian official: Obama climbed to the top of the tree, \"doesn\\'t know how to get down\"\\nObama sends a letter to the heads of the House and Senate .\\nObama to seek congressional approval on military action against Syria .\\nAim is to determine whether CW were used, not by whom, says U.N. spokesman .'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "['Syrian official: Obama climbed to the top of the tree, \"doesn\\'t know how to get down\"',\n 'Obama sends a letter to the heads of the House and Senate .',\n 'Obama to seek congressional approval on military action against Syria .',\n 'Aim is to determine whether CW were used, not by whom, says U.N. spokesman .']"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0].split(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from transformers import PegasusTokenizerFast\n",
    "\n",
    "model_name = \"google/pegasus-large\"\n",
    "\n",
    "tokenizer = PegasusTokenizerFast.from_pretrained(model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from transformers import PegasusForConditionalGeneration\n",
    "\n",
    "model: PegasusForConditionalGeneration = PegasusForConditionalGeneration.from_pretrained(model_name).to(\"cuda\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class PegasusDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        # TODO - check what this is\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels['input_ids'][idx])  # torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels['input_ids'])  # len(self.labels)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "from transformers import BatchEncoding\n",
    "\n",
    "texts, labels = train_texts[:10], train_labels[:10]\n",
    "max_input_length = 512\n",
    "max_target_length = 128\n",
    "encodings = tokenizer(texts, max_length=512, truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
    "\n",
    "with tokenizer.as_target_tokenizer():\n",
    "    encoded_labels = tokenizer(labels, max_length=max_target_length, truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
    "\n",
    "# tokenized_dataset = dataset.map(preprocessing_function, batched=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "dataset = PegasusDataset(encodings, encoded_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "encodings = encodings.to(\"cuda\")\n",
    "output = model.generate(**encodings)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "10"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([    0,  1276, 12998,  3531,  1728, 11895,   112,  9835,   115,   124,\n          682,   112,   207,  2002,  1937,   115,  6881,   107,  3531,  1406,\n          114,  1801,   112,   109,  4082,   113,   109,  1087,   111,  4533,\n          124,  1327,   565,   108,   539,   244, 13501,   120,   178,  3999,\n         2002,   918,   464, 10298,  5128,   117,   109,   268,   863,   112,\n          248,   204,   109,  6854,   207,   113,  3568,  4841,   107,   139,\n         2962,  4024,   135,  3531,  6937,  3108,   112,  9572,   109,   207,\n          113,  2002,  1937,   198,   497, 20438,   108, 17027,   108,  1585,\n          111, 30189,   109,   866,   118,   533,  1481,   113,  3568,  4841,\n          132,   176,  4841,   113,  2977,  7601,   496,   168,   131,   116,\n          114,   863,   120,   117,   323,   112,   795,   142,   942,  3533,\n          190,   114, 13598,  2970,  1488,  2949,   107, 23195,   518,  6881,\n          108,  4069,  1812,   120,   138,  1735,   682,  3568,  4841,   195,\n          263,   115,   142,  2281,   616,   289,   396,   115,   114, 31130,\n        16907,   107,   343,   170,   263,   109,  4841,   115,   109,  1668,\n         7304,  1503,  2281,   115,   114, 31130, 16907,   124,  1508,  1616,\n          148,   174,   114,   662,   491,   113,  1122,  4170,   204,   109,\n        10298,  3533,   107,     1,     0], device='cuda:0')"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "decoded_output = tokenizer.batch_decode(output, skip_special_tokens=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "'\"And when factoring all of those in, it was determined that he was the best candidate, even in light of the cost that would be incurred.\" Klumb called the GSA\\'s teleworking program \"a successful program that\\'s going to lead to cost savings for taxpayers.\" But a GSA spokeswoman said, \"We are not going to defend this type of travel.\" And a GSA employee in Kansas City, who requested anonymity, said that hiring someone in Hawaii to work for the Kansas City region was ludicrous. It would have reduced the cost of travel by at least 70 percent when you look at just the airfare of what it takes to from Honolulu to Washington, D.C., where a lot of business is done.\" Dan Tangherlini, who was appointed acting GSA administrator this year, said the agency was examining the cost of the entire teleworking program.'"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_output[2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': tensor([[10298,  1571,   151,  3531, 14026,   112,   109,   349,   113,   109,\n          1681,   108,   198, 56019,   131,   144,   235,   199,   112,   179,\n           308,   194,  3531,  9274,   114,  1801,   112,   109,  4082,   113,\n           109,  1087,   111,  4533,   110,   107,  3531,   112,  2395, 17250,\n          3619,   124,  2002,   918,   464,  6881,   110,   107, 22848,   117,\n           112,  1735,   682, 17783,   195,   263,   108,   146,   141,  2901,\n           108,   649,   475,   107,  1400,   107,  9619,   110,   107,     1,\n             0,     0],\n        [84434, 23093,  4777,   776,  1460,   113,   278,  6906,   110,   107,\n         22371,   116, 14236,   112,   384,   757,  5391,   208, 11414,  3669,\n           110,   107, 44517,  1460,   134,   109, 17461,   118, 23093,   110,\n           107, 14236,  1394,   164,   115,   652,   131,   116,   384,   757,\n          5391,   208, 11414,   110,   107,     1,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0],\n        [  139,  2307,   115,  2102,   131,   116,  5670,   672,   629,   117,\n           790,  2490,   113,   198, 34029,   194,  1841,   110,   107,   139,\n          2307,   131,   116,   905,   112,   111,   135,   109, 15372,   475,\n           107,   283,   107,   289,   232,   519,   154,   197, 93294,   110,\n           107,   139, 77192,   431,   108,   172,   149, 48786,  1895,   108,\n           117,   365,   933,   110,   107,     1,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0],\n        [ 6053,   151,   202,  3066,  2214,   649,   265,   140,   297,   113,\n           114,   320, 12261,  5849, 37529, 19846,   115,  2652,   110,   107,\n          6053,   151, 47104,   151,   198,  4380,   144,  2675,   108,  3726,\n          3905,   108,   450,   121, 38516,  1743,  6006,   111,  4530,   194,\n         37529, 19846,   117,   163,  9987,   115,   114,  2546, 47041, 11957,\n           108,  2662,   416,   110,   107, 33712,   116,   697,   109,  2546,\n          1146,   323,   114,  4211,   113,  9811,   115,  2726,  3072,   110,\n           107,     1],\n        [ 3314,  7170,   266,   115, 10171, 12841,   326,   833,  1310,   399,\n           110,   107, 35755,   416,   164,   112,   599,   200,   635,   297,\n           132,  5121,   111,  4524,   109,  8171,   110,   107,  5107, 14760,\n          2893,   115,  1462,  1789,   206,   339,  8278, 65376, 38284,   110,\n           107,     1,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0],\n        [45076,  1211,  1337, 14941,  9045,   115,   156,  3082,   108,   114,\n           475,   107,  1400,   107,  1571,   649,   110,   107,  8858,   133,\n         15307,   482,   109,  3660,   112,   475,   107,  1400,   107,  9245,\n           115, 27558,   108,   178,   649,   110,   107,   182,  4083,  3613,\n           120,  3040,   624,   475,   107,  1400,   107, 80017,   111,   608,\n         15310,   110,   107,     1,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0],\n        [ 6053,   151,   384,  1211,  4432,  1165,  1459,   115,  7045,   110,\n           107,   655,  5350, 61188,  2539,   108, 53297,   113,  4599,   108,\n           765, 13498,  2144,   900, 24699,   775,   110,   107,  6517,   655,\n          6797,  7660,   111, 11263,  3911,   163,  3195,   112,   126,   110,\n           107,   322,   416,   775,  7168, 10589, 24535,   108,   155,  6204,\n           416,   126,   591,   131,   144,  4721,   189,  4383,  4091,   110,\n           107,     1,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0],\n        [ 7311,  1066,   117,   109, 22945,   370,   113,   922,   111,   109,\n         22945,   388,   112,  1541,   578,   110,   107,   398,   249,   130,\n         75623,  1722,   256,   129,  1363,   124,  2429,   118,   136, 30178,\n          2974,   110,   107,  1063,   127,   668,   355,   121, 21887,  5915,\n           118,   219, 30178,   116,   110,   107,     1,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0],\n        [ 6053,   151,  3339, 26628,  5767,   178,   196,   174,  2609,   118,\n           539,   269,  1564,  2783,   110,   107,  3532,   545,  2372,   112,\n           403,   109, 11872,  5448,   111, 79084,   110,   107,   139, 11872,\n           111, 10256,  8464,   140,   135,   109, 86127,  1322,   115,  4905,\n          3397,   110,   107,     1,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0],\n        [  139,  2413,  3890,   140,   784,   112,   114,  2241,  1342,   110,\n           107, 83959,   118,  2241,   649, 15855, 22351,  4192,   270,  2839,\n           118, 12378,   108,  1458,  1367,   618,   110,   107,   285,   196,\n           174,   134,   114,  1151,   131,   116,   238,   115,  1741,   449,\n           244,   169,  1750,   635,   342,   186,   110,   107,   452,   148,\n           174, 36177,   273,   122,   339,   863, 27600,   204,   109,  2413,\n          4217,   131,   116,   406,   110,   107,     1,     0,     0,     0,\n             0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]])}"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "\"Usain Bolt wins third gold of world championship. Anchors Jamaica to 4x100m relay victory. Eighth gold at the championships for Bolt. Jamaica double up in women's 4x100m relay.\""
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tokenizer.as_target_tokenizer():\n",
    "    supposed_output = tokenizer.batch_decode(encoded_labels[\"input_ids\"], skip_special_tokens=True)\n",
    "\n",
    "supposed_output[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['input_ids', 'attention_mask'])"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_labels.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jvidakovic/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "['NEW: A Canadian doctor says she was part of a team examining Harry Burkhart in 2010.',\n 'NEW: Diagnosis: \"autism, severe anxiety, post-traumatic stress disorder and depression\" Burkhart is also suspected in a German arson probe, officials say.',\n 'Prosecutors believe the German national set a string of fires in Los Angeles.']"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.sent_tokenize(supposed_output[3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# okay this works\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    # labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)  # not sure if using stemmer is correct here\n",
    "\n",
    "    # Extract a few results\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    result[\"rougecomb\"] = result[\"rouge1\"] + 2 * result[\"rouge2\"] + result[\"rougeLsum\"]\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers.training_args import OptimizerNames\n",
    "from transformers import Seq2SeqTrainingArguments, IntervalStrategy, SchedulerType\n",
    "\n",
    "batch_size=1\n",
    "output_dir = \"few-shot-results\"\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=output_dir,  # output directory\n",
    "    max_steps=2000,\n",
    "    per_device_train_batch_size=1,  # batch size per device during training, can increase if memory allows\n",
    "    per_device_eval_batch_size=1,  # batch size for evaluation, can increase if memory allows\n",
    "    gradient_accumulation_steps=128,\n",
    "    eval_accumulation_steps=128,\n",
    "    # save_steps=100,  # number of updates steps before checkpoint saves\n",
    "    save_steps=1,\n",
    "    save_total_limit=1,  # limit the total amount of checkpoints and deletes the older checkpoints\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model = \"rougecomb\",\n",
    "    greater_is_better=True,\n",
    "    evaluation_strategy=IntervalStrategy.STEPS,  # evaluation strategy to adopt during training\n",
    "    eval_steps=1,  # number of update steps before evaluation\n",
    "    # eval_steps = 100\n",
    "    logging_dir='./test-logs',  # directory for storing logs\n",
    "    logging_steps=10,\n",
    "    adafactor=True,\n",
    "    optim=OptimizerNames.ADAFACTOR,\n",
    "    lr_scheduler_type=SchedulerType.CONSTANT\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}